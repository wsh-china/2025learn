#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from wordcloud import WordCloud
import argparse
import os
import matplotlib.font_manager as fm

# é¢„è®¾çš„é…è‰²æ–¹æ¡ˆï¼ˆä¸ºä¸åŒçš„GOç±»åˆ«è®¾è®¡ï¼‰
COLOR_SCHEMES = {
    'BP': [(0, 0.5, 0.8), (0, 0.7, 1), (0.1, 0.8, 1)],  # è“è‰²ç³»
    'CC': [(0, 0.6, 0.3), (0.2, 0.8, 0.4), (0.4, 0.9, 0.5)],  # ç»¿è‰²ç³»
    'MF': [(0.7, 0.1, 0.2), (0.9, 0.2, 0.3), (1, 0.4, 0.4)],  # çº¢è‰²ç³»
    'ALL': [(0.5, 0, 0.8), (0.3, 0.3, 0.9), (0, 0.6, 0.6), (0.1, 0.8, 0.4)],  # æ··åˆè‰²ç³»
    # å…¶ä»–é¢„è®¾æ–¹æ¡ˆ
    'blue_purple': [(0.1, 0.1, 0.9), (0.5, 0, 0.8), (0.8, 0.1, 0.5)],
    'scientific': [(0, 0.3, 0.7), (0, 0.5, 0.5), (0.1, 0.7, 0.4)],
    'elegant': [(0.2, 0.2, 0.5), (0.4, 0.2, 0.4), (0.6, 0.2, 0.3)]
}

def list_available_fonts():
    """åˆ—å‡ºç³»ç»Ÿå¯ç”¨çš„å­—ä½“"""
    fonts = sorted([f.name for f in fm.fontManager.ttflist])
    return fonts

def get_font_path(font_name):
    """è·å–æŒ‡å®šå­—ä½“çš„è·¯å¾„"""
    if not font_name:
        return None

    # æ£€æŸ¥æ˜¯å¦æ˜¯æ–‡ä»¶è·¯å¾„
    if os.path.isfile(font_name) and (font_name.endswith('.ttf') or font_name.endswith('.otf')):
        return font_name

    # æŸ¥æ‰¾ç³»ç»Ÿå­—ä½“
    fonts = [f for f in fm.fontManager.ttflist if font_name.lower() in f.name.lower()]
    if fonts:
        return fonts[0].fname
    return None

def filter_by_ontology(df, ontology=None):
    """æ ¹æ®æœ¬ä½“ç±»åˆ«ç­›é€‰æ•°æ®"""
    if ontology is None or ontology.upper() == 'ALL':
        return df
    return df[df['ONTOLOGY'] == ontology.upper()]

def generate_go_wordcloud(input_file, output_prefix='go_wordcloud', use_id=False,
                         width=1200, height=800, background_color="white", max_words=1000,
                         font_name=None, color_scheme=None, random_state=42,
                         generate_all=True, generate_bp=True, generate_cc=True, generate_mf=True):
    """ç”ŸæˆGOå¯Œé›†ç»“æœçš„è¯äº‘å›¾"""

    # è¯»å–æ•°æ®
    try:
        df = pd.read_csv(input_file)
    except:
        try:
            df = pd.read_csv(input_file, sep="\t")
        except Exception as e:
            print(f"âŒ æ— æ³•è¯»å–è¾“å…¥æ–‡ä»¶: {e}")
            return False

    # æ£€æŸ¥å¿…è¦åˆ—
    required_cols = ['ID', 'Description', 'ONTOLOGY', 'OccurrenceCount']
    missing_cols = [col for col in required_cols if col not in df.columns]
    if missing_cols:
        print(f"âŒ è¾“å…¥æ–‡ä»¶ç¼ºå°‘å¿…è¦çš„åˆ—: {', '.join(missing_cols)}")
        return False

    # è·å–å­—ä½“è·¯å¾„
    font_path = get_font_path(font_name)
    if font_name and font_path:
        print(f"âœ… ä½¿ç”¨å­—ä½“: {font_name}")
    elif font_name:
        print(f"âš ï¸ æ‰¾ä¸åˆ°å­—ä½“ '{font_name}'ï¼Œä½¿ç”¨é»˜è®¤å­—ä½“")
        font_path = None

    # ç¡®å®šè¯äº‘ä½¿ç”¨çš„æ–‡æœ¬å­—æ®µ
    text_field = 'ID' if use_id else 'Description'

    # åˆ›å»ºå®Œæ•´çš„è¯é¢‘å­—å…¸ï¼ˆç”¨äº ALL åˆ†ç±»ï¼‰
    all_freq_dict = dict(zip(df[text_field], df['OccurrenceCount']))
    global_max_freq = max(all_freq_dict.values())  # å…¨å±€æœ€å¤§é¢‘ç‡

    # è®¾ç½®æ¯ä¸ªGOç±»åˆ«çš„é…è‰²å’Œè¾“å‡ºæ–‡ä»¶å
    ontology_settings = {
        'ALL': {'color': 'ALL', 'title': 'æ‰€æœ‰GOæ¡ç›®è¯äº‘å›¾', 'file': f"{output_prefix}_all.png"},
        'BP': {'color': 'BP', 'title': 'ç”Ÿç‰©è¿‡ç¨‹(BP)è¯äº‘å›¾', 'file': f"{output_prefix}_bp.png"},
        'CC': {'color': 'CC', 'title': 'ç»†èƒç»„åˆ†(CC)è¯äº‘å›¾', 'file': f"{output_prefix}_cc.png"},
        'MF': {'color': 'MF', 'title': 'åˆ†å­åŠŸèƒ½(MF)è¯äº‘å›¾', 'file': f"{output_prefix}_mf.png"}
    }

    # åˆ¤æ–­éœ€è¦ç”Ÿæˆå“ªäº›è¯äº‘å›¾
    generate_flags = {
        'ALL': generate_all,
        'BP': generate_bp,
        'CC': generate_cc,
        'MF': generate_mf
    }

    # ç”Ÿæˆå„ä¸ªGOç±»åˆ«çš„è¯äº‘å›¾
    for ontology, settings in ontology_settings.items():
        if not generate_flags[ontology]:
            continue

        # æ ¹æ®æœ¬ä½“ç±»åˆ«ç­›é€‰æ•°æ®
        filtered_df = filter_by_ontology(df, ontology)

        if len(filtered_df) == 0:
            print(f"âš ï¸ æ²¡æœ‰æ‰¾åˆ°{ontology}ç±»åˆ«çš„GOæ¡ç›®ï¼Œè·³è¿‡ç”Ÿæˆè¯äº‘å›¾")
            continue

        # åˆ›å»ºè¯¥ç±»åˆ«çš„è¯é¢‘å­—å…¸
        freq_dict = dict(zip(filtered_df[text_field], filtered_df['OccurrenceCount']))

        # å¦‚æœè¯å…¸ä¸ºç©ºï¼Œè·³è¿‡
        if not freq_dict:
            print(f"âš ï¸ {ontology}ç±»åˆ«çš„è¯é¢‘å­—å…¸ä¸ºç©ºï¼Œè·³è¿‡ç”Ÿæˆè¯äº‘å›¾")
            continue

        print(f"ğŸ” ä¸º{ontology}ç±»åˆ«ç”Ÿæˆè¯äº‘å›¾ï¼ŒåŒ…å«{len(freq_dict)}ä¸ªGOæ¡ç›®")

        # è·å–ç‰¹å®šGOç±»åˆ«çš„é…è‰²æ–¹æ¡ˆ
        go_color_scheme = color_scheme if color_scheme else settings['color']

        # åˆ›å»ºé¢œè‰²å‡½æ•°
        if go_color_scheme in COLOR_SCHEMES:
            colors = COLOR_SCHEMES[go_color_scheme]

            def custom_color_func(word, font_size, position, orientation, random_state=None, **kwargs):
                """æ ¹æ®è¯é¢‘å’Œé¢„è®¾é…è‰²æ–¹æ¡ˆåˆ›å»ºé¢œè‰²"""
                # è·å–è¯çš„é¢‘ç‡
                freq = freq_dict.get(word, 1)
                # å½’ä¸€åŒ–é¢‘ç‡ï¼ˆä½¿ç”¨å…¨å±€æœ€å¤§é¢‘ç‡ï¼‰
                freq_norm = min(1.0, freq / global_max_freq)

                # æ ¹æ®é¢‘ç‡åœ¨é¢œè‰²åˆ—è¡¨ä¸­æ’å€¼
                idx = min(int(freq_norm * (len(colors) - 1) * 100), len(colors) - 2)
                start_color = colors[idx // 100]
                end_color = colors[min(idx // 100 + 1, len(colors) - 1)]
                t = (idx % 100) / 100.0

                # çº¿æ€§æ’å€¼
                r = start_color[0] * (1-t) + end_color[0] * t
                g = start_color[1] * (1-t) + end_color[1] * t
                b = start_color[2] * (1-t) + end_color[2] * t

                return (int(r*255), int(g*255), int(b*255))

            color_func = custom_color_func
        else:
            color_func = None

        # åˆ›å»ºè¯äº‘å¯¹è±¡
        wc = WordCloud(
            width=width,
            height=height,
            background_color=background_color,
            max_words=max_words,
            color_func=color_func,
            prefer_horizontal=0.9,
            min_font_size=10,
            max_font_size=180,
            font_step=1,
            collocations=False,
            relative_scaling=0.5,
            regexp=r"[\w\s\:\-]+",
            font_path=font_path,
            random_state=random_state
        )

        # å¯¹äº ALL åˆ†ç±»ï¼Œä½¿ç”¨å®Œæ•´çš„è¯é¢‘å­—å…¸
        if ontology == 'ALL':
            wordcloud_data = all_freq_dict
        else:
            wordcloud_data = freq_dict

        # ç”Ÿæˆè¯äº‘
        wc.generate_from_frequencies(wordcloud_data)

        # åˆ›å»ºå›¾å½¢å¹¶æ˜¾ç¤º
        plt.figure(figsize=(width/100, height/100), dpi=100, facecolor=background_color)
        plt.imshow(wc, interpolation='bilinear')
        plt.axis("off")
        plt.tight_layout(pad=0)

        # ä¿å­˜å›¾ç‰‡
        output_file = settings['file']
        try:
            plt.savefig(output_file, dpi=300, bbox_inches='tight', facecolor=background_color)
            print(f"âœ… {ontology}è¯äº‘å›¾å·²ä¿å­˜åˆ°: {output_file}")
        except Exception as e:
            print(f"âŒ ä¿å­˜{ontology}è¯äº‘å›¾å¤±è´¥: {str(e)}")

        plt.close()

    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    bp_count = len(df[df['ONTOLOGY'] == 'BP'])
    cc_count = len(df[df['ONTOLOGY'] == 'CC'])
    mf_count = len(df[df['ONTOLOGY'] == 'MF'])

    print(f"\nğŸ“Š GOå¯Œé›†ç»“æœç»Ÿè®¡:")
    print(f"  â€¢ æ€»GOæ¡ç›®: {len(df)}ä¸ª")
    print(f"  â€¢ ç”Ÿç‰©è¿‡ç¨‹(BP): {bp_count}ä¸ª")
    print(f"  â€¢ ç»†èƒç»„åˆ†(CC): {cc_count}ä¸ª")
    print(f"  â€¢ åˆ†å­åŠŸèƒ½(MF): {mf_count}ä¸ª")

    return True

def main():
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='ç”ŸæˆGOå¯Œé›†ç»“æœè¯äº‘å›¾')
    parser.add_argument('-i', '--input', required=True,
                        help='è¾“å…¥çš„GOå¯Œé›†ç»Ÿè®¡CSV/TSVæ–‡ä»¶ï¼ŒåŒ…å«IDã€Descriptionã€ONTOLOGYå’ŒOccurrenceCountåˆ—')
    parser.add_argument('-o', '--output', default='go_wordcloud',
                        help='è¾“å‡ºçš„è¯äº‘å›¾æ–‡ä»¶å‰ç¼€ (é»˜è®¤: go_wordcloud)')
    parser.add_argument('-id', '--use-id', action='store_true',
                        help='ä½¿ç”¨GO IDè€Œä¸æ˜¯GOæè¿°ç”Ÿæˆè¯äº‘å›¾')
    parser.add_argument('-w', '--width', type=int, default=1200,
                        help='è¯äº‘å›¾å®½åº¦ (åƒç´ , é»˜è®¤: 1200)')
    parser.add_argument('-H', '--height', type=int, default=800,
                        help='è¯äº‘å›¾é«˜åº¦ (åƒç´ , é»˜è®¤: 800)')
    parser.add_argument('-b', '--background', default='white',
                        help='èƒŒæ™¯é¢œè‰² (é»˜è®¤: white)')
    parser.add_argument('-n', '--max-words', type=int, default=1000,
                        help='æœ€å¤§æ˜¾ç¤ºè¯æ•° (é»˜è®¤: 1000)')
    parser.add_argument('-f', '--font', default=None,
                        help='æŒ‡å®šå­—ä½“åç§°æˆ–TTFæ–‡ä»¶è·¯å¾„ (é»˜è®¤: ç³»ç»Ÿé»˜è®¤å­—ä½“)')
    parser.add_argument('-s', '--scheme', default=None,
                        help=f'é…è‰²æ–¹æ¡ˆï¼Œå¯é€‰: {", ".join(COLOR_SCHEMES.keys())} (é»˜è®¤: æ ¹æ®GOç±»åˆ«è‡ªåŠ¨é€‰æ‹©)')
    parser.add_argument('-r', '--random-state', type=int, default=42,
                        help='éšæœºç§å­ï¼Œç”¨äºæ§åˆ¶è¯çš„ä½ç½® (é»˜è®¤: 42)')
    parser.add_argument('-l', '--list-fonts', action='store_true',
                        help='åˆ—å‡ºç³»ç»Ÿå¯ç”¨çš„å­—ä½“')
    parser.add_argument('--no-all', action='store_true',
                        help='ä¸ç”ŸæˆåŒ…å«æ‰€æœ‰GOç±»åˆ«çš„è¯äº‘å›¾')
    parser.add_argument('--no-bp', action='store_true',
                        help='ä¸ç”ŸæˆBPç±»åˆ«çš„è¯äº‘å›¾')
    parser.add_argument('--no-cc', action='store_true',
                        help='ä¸ç”ŸæˆCCç±»åˆ«çš„è¯äº‘å›¾')
    parser.add_argument('--no-mf', action='store_true',
                        help='ä¸ç”ŸæˆMFç±»åˆ«çš„è¯äº‘å›¾')

    args = parser.parse_args()

    # åˆ—å‡ºå­—ä½“
    if args.list_fonts:
        fonts = list_available_fonts()
        print("ç³»ç»Ÿå¯ç”¨å­—ä½“:")
        for i, font in enumerate(fonts, 1):
            print(f"{i}. {font}")
        return

    # ç”Ÿæˆè¯äº‘
    generate_go_wordcloud(
        args.input, args.output, args.use_id,
        args.width, args.height, args.background, args.max_words,
        args.font, args.scheme, args.random_state,
        not args.no_all, not args.no_bp, not args.no_cc, not args.no_mf
    )

if __name__ == "__main__":
    main()